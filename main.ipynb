{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "time_step = 10\n",
    "max_time = 5400\n",
    "\n",
    "content = np.loadtxt(\"Data\\students003.txt\")\n",
    "max_id = int(np.max(content[:, 1]))\n",
    "max_time = int(np.max(content[:, 0]) / time_step) + 1\n",
    "\n",
    "t_id_fxy = np.zeros((max_time, max_id, 2))\n",
    "\n",
    "for l in content:\n",
    "    t_id_fxy[int(l[0] / time_step), int(l[1] - 1), :] = l[-2:]\n",
    "\n",
    "t_id_fxy = torch.from_numpy(t_id_fxy).float()\n",
    "delta_xy = t_id_fxy[1:] - t_id_fxy[:-1]\n",
    "delta_xy = torch.cat([torch.zeros(1, max_id, 2), delta_xy])\n",
    "zero_idx = torch.argwhere(t_id_fxy[:, :, 0] == 0)\n",
    "for z_idx in zero_idx:\n",
    "    t, i = z_idx\n",
    "    delta_xy[t, i, :] = 0\n",
    "    if t < int(max_time / time_step):\n",
    "        delta_xy[t + 1, i, :] = 0\n",
    "\n",
    "t_id_fxy_vxvy = torch.cat([t_id_fxy, delta_xy], dim=-1)\n",
    "torch.save(t_id_fxy_vxvy, \"Data\\\\track.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k_means 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from src.clustering import k_means\n",
    "from src.draw import Drawer\n",
    "\n",
    "track = torch.load(\"Data\\\\track.pt\")\n",
    "max_x = torch.max(track[:, :, 0])\n",
    "min_x = torch.min(track[:, :, 0])\n",
    "max_y = torch.max(track[:, :, 1])\n",
    "min_y = torch.min(track[:, :, 1])\n",
    "\n",
    "k = 5\n",
    "d = Drawer(min_x, max_x, min_y, max_y)\n",
    "\n",
    "video_output = 'Videos\\\\kmeans_1.mp4'\n",
    "fps=30\n",
    "video = cv2.VideoWriter(video_output, 0, fps, (420, 380))\n",
    "\n",
    "for i in range(track.shape[0]):\n",
    "    t = track[i]\n",
    "    idx = torch.argwhere(t[:, 0] != 0)\n",
    "    idx = idx[:, 0]\n",
    "    t = t[idx]\n",
    "    t = t[:, :2]\n",
    "    clu = k_means(t, k)\n",
    "\n",
    "    canvas = d.draw(clu)\n",
    "    video.write(canvas)\n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from src.draw import Drawer, org_data\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "track = torch.load(\"Data\\\\track.pt\")\n",
    "max_x = torch.max(track[:, :, 0])\n",
    "min_x = torch.min(track[:, :, 0])\n",
    "max_y = torch.max(track[:, :, 1])\n",
    "min_y = torch.min(track[:, :, 1])\n",
    "\n",
    "k = 5\n",
    "d = Drawer(min_x, max_x, min_y, max_y)\n",
    "kmeans = KMeans(n_clusters=k, n_init=5)\n",
    "\n",
    "video_output = \"Videos\\\\kmeans_2.mp4\"\n",
    "fps = 30\n",
    "video = cv2.VideoWriter(video_output, 0, fps, (420, 380))\n",
    "\n",
    "for i in range(track.shape[0]):\n",
    "    t = track[i]\n",
    "    idx = torch.argwhere(t[:, 0] != 0)\n",
    "    idx = idx[:, 0]\n",
    "    t = t[idx]\n",
    "    t = t[:, :2]\n",
    "    kmeans.fit(t)\n",
    "    clu = org_data(t, kmeans.labels_)\n",
    "    canvas = d.draw(clu)\n",
    "\n",
    "    video.write(canvas)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from sklearn.cluster import DBSCAN\n",
    "from src.draw import Drawer, org_data\n",
    "\n",
    "track = torch.load(\"Data\\\\track.pt\")\n",
    "max_x = torch.max(track[:, :, 0])\n",
    "min_x = torch.min(track[:, :, 0])\n",
    "max_y = torch.max(track[:, :, 1])\n",
    "min_y = torch.min(track[:, :, 1])\n",
    "\n",
    "db = DBSCAN(eps=2, min_samples=1)\n",
    "d = Drawer(min_x, max_x, min_y, max_y)\n",
    "\n",
    "video_output = \"Videos\\\\DBSAN.mp4\"\n",
    "fps = 30\n",
    "video = cv2.VideoWriter(video_output, 0, fps, (420, 380))\n",
    "\n",
    "for i in range(track.shape[0]):\n",
    "    t = track[i]\n",
    "    idx = torch.argwhere(t[:, 0] != 0)\n",
    "    idx = idx[:, 0]\n",
    "    t = t[idx]\n",
    "    t = t[:, :2]\n",
    "    db.fit(t)\n",
    "    clu = org_data(t, db.labels_)\n",
    "    canvas = d.draw(clu)\n",
    "    video.write(canvas)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层次聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from src.draw import Drawer, org_data\n",
    "\n",
    "track = torch.load(\"Data\\\\track.pt\")\n",
    "max_x = torch.max(track[:, :, 0])\n",
    "min_x = torch.min(track[:, :, 0])\n",
    "max_y = torch.max(track[:, :, 1])\n",
    "min_y = torch.min(track[:, :, 1])\n",
    "\n",
    "k = 5\n",
    "clustering = AgglomerativeClustering(n_clusters=5, linkage=\"ward\")\n",
    "d = Drawer(min_x, max_x, min_y, max_y)\n",
    "\n",
    "\n",
    "video_output = \"Videos\\\\AGNES.mp4\"\n",
    "fps = 30\n",
    "video = cv2.VideoWriter(video_output, 0, fps, (420, 380))\n",
    "\n",
    "for i in range(track.shape[0]):\n",
    "    t = track[i]\n",
    "    idx = torch.argwhere(t[:, 0] != 0)\n",
    "    idx = idx[:, 0]\n",
    "    t = t[idx]\n",
    "    t = t[:, :2]\n",
    "    clustering.fit(t)\n",
    "    clu = org_data(t, clustering.labels_)\n",
    "    canvas = d.draw(clu)\n",
    "    video.write(canvas)\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
